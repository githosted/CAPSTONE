{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install numpy==1.21.2\\n!pip install seaborn==0.11.1\\n!pip install matplotlib==3.4.3\\n!pip install statsmodels==0.12.2\\n!pip install pandas==1.2.4\\n!pip install scipy==1.6.3\\n!pip install scikit_learn==0.24.2\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#required packages with versions\n",
    "\"\"\"\n",
    "!pip install numpy==1.21.2\n",
    "!pip install seaborn==0.11.1\n",
    "!pip install matplotlib==3.4.3\n",
    "!pip install statsmodels==0.12.2\n",
    "!pip install pandas==1.2.4\n",
    "!pip install scipy==1.6.3\n",
    "!pip install scikit_learn==0.24.2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (Temp/ipykernel_7580/159889924.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\racar\\AppData\\Local\\Temp/ipykernel_7580/159889924.py\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    df=pd.read_csv(data\\\\.'EPL_Soccer_MLR_LR.csv')\u001b[0m\n\u001b[1;37m                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "#Package imports needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import scipy\n",
    "\n",
    "\n",
    "#Load the data as a data frame\n",
    "df=pd.read_csv(data\\\\.'EPL_Soccer_MLR_LR.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get basic description of the data, looking the spread of the different variables,\n",
    "# along with  abrupt changes between the minimum, 25th, 50th, 75th, and max for the different variables\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Get info, look for missing values, get a sense of what format each variable is in\n",
    "\n",
    "\n",
    "df.info()\n",
    "#We are attempting to predict score\n",
    "#Look at correlations between variables to identify best predictor for response (score)\n",
    "df.corr()\n",
    "\n",
    "#Can see the strongest predictor of score is cost, with a 96% correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Let's plot cost vs. score\n",
    "plt.scatter(df['Cost'], df['Score']);\n",
    "\n",
    "#Strong linear association between cost and score, maybe some concern with model\n",
    "# after a cost of 125 or so!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Assign x, y then do training testing split\n",
    "x=df['Cost']\n",
    "y=df['Score']\n",
    "\n",
    "#Splitting with 75% training, 25% testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.75,\n",
    "                                                    test_size = 0.25, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#statsmodel approach to regression\n",
    "# fit the model\n",
    "lr = sm.OLS(y_train, x_train).fit()\n",
    "\n",
    "# Printing the parameters\n",
    "lr.params\n",
    "lr.summary()\n",
    "\n",
    "#force intercept term\n",
    "x_train_with_intercept = sm.add_constant(x_train)\n",
    "lr = sm.OLS(y_train, x_train_with_intercept).fit()\n",
    "lr.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Extract the B0, B1\n",
    "print(lr.params)\n",
    "b0=lr.params[0]\n",
    "b1=lr.params[1]\n",
    "\n",
    "#Plot the fitted line on training data\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.plot(x_train, b0+ b1*x_train, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Plot the fitted line on test data\n",
    "\n",
    "x_test_with_intercept = sm.add_constant(x_test)\n",
    "y_test_fitted = lr.predict(x_test_with_intercept)\n",
    "\n",
    "\n",
    "plt.scatter(x_test, y_test)\n",
    "plt.plot(x_test, y_test_fitted, 'r')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#DIAGNOSTICS\n",
    "\n",
    "#CHECKLIST:\n",
    "# NON-LINEARITY\n",
    "# NON-CONSTANT VARIANCE\n",
    "# DEVIATIONS FROM NORMALITY\n",
    "# ERRORS NOT IID\n",
    "# OUTLIERS\n",
    "# MISSING PREDICTORS\n",
    "\n",
    "\n",
    "\n",
    "#Build predictions on training data\n",
    "predictions_y = lr.predict(x_train_with_intercept)\n",
    "\n",
    "#Find residuals\n",
    "r_i = (y_train - predictions_y)\n",
    "\n",
    "\n",
    "#Residuals vs. predictor in training data\n",
    "plt.title(' Residuals vs. Cost')\n",
    "plt.xlabel('Cost',fontsize=15)\n",
    "plt.scatter(x_train, r_i)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Absolute residuals against predictor\n",
    "abs_r_i = np.abs(y_train - predictions_y)\n",
    "plt.title('Absolute Residuals vs. Cost')\n",
    "plt.xlabel('Cost',fontsize=15)\n",
    "plt.scatter(x_train, abs_r_i)\n",
    "plt.show()\n",
    "\n",
    "#Normality plot\n",
    "scipy.stats.probplot(r_i,plot=plt)\n",
    "\n",
    "#Tails might be a little heavy, but overall no clear reason to reject normality expectations\n",
    "# Evaluate normality through histogram of residuals\n",
    "# Plotting the histogram using the residual values\n",
    "fig = plt.figure()\n",
    "sns.distplot(r_i, bins = 15)\n",
    "plt.title('Error Terms', fontsize = 15)\n",
    "plt.xlabel('y_train - y_train_pred', fontsize = 15)\n",
    "plt.show()\n",
    "\n",
    "#Boxplot for outliers\n",
    "# plot\n",
    "plt.boxplot(r_i, boxprops=dict(color='red'))\n",
    "plt.title('Residual Boxplot');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Demo of how to deal with non-constant variance through transformations\n",
    "\n",
    "test_residuals=(y_test-y_test_fitted)\n",
    "len(y_test)\n",
    "len(y_test_fitted)\n",
    "len(test_residuals)\n",
    "\n",
    "#Residuals vs. predictor in test set\n",
    "plt.title('Test Residuals vs. Cost')\n",
    "plt.xlabel('Cost',fontsize=15)\n",
    "plt.scatter(x_test, test_residuals)\n",
    "plt.show()\n",
    "\n",
    "#Some evidence of non-constant variance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "#Try sqrt\n",
    "sqrt_y=np.sqrt(y)\n",
    "plt.scatter(x, sqrt_y,color='red');\n",
    "\n",
    "#Try ln\n",
    "ln_y=np.log(y)\n",
    "plt.scatter(x, ln_y,color='blue');\n",
    "\n",
    "\n",
    "#Let's try a BC transformation\n",
    "\n",
    "#Box Cox procedure on all cost\n",
    "bc_y=list(stats.boxcox(y))\n",
    "bc_y=bc_y[0]\n",
    "plt.scatter(x, bc_y,color='orange');\n",
    "\n",
    "#Overall, most satisfied with the sqrt transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Run regression on this set\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, sqrt_y, train_size = 0.75,\n",
    "                                                    test_size = 0.25, random_state = 100)\n",
    "\n",
    "\n",
    "#force intercept term\n",
    "x_train_with_intercept = sm.add_constant(x_train)\n",
    "lr = sm.OLS(y_train, x_train_with_intercept).fit()\n",
    "lr.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Extract the B0, B1\n",
    "print(lr.params)\n",
    "b0=lr.params[0]\n",
    "b1=lr.params[1]\n",
    "\n",
    "#Plot the fitted line on training data\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.plot(x_train, b0+ b1*x_train, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Plot the fitted line on test data\n",
    "\n",
    "x_test_with_intercept = sm.add_constant(x_test)\n",
    "y_test_fitted = lr.predict(x_test_with_intercept)\n",
    "\n",
    "\n",
    "plt.scatter(x_test, y_test)\n",
    "plt.plot(x_test, y_test_fitted, 'r')\n",
    "plt.show()\n",
    "\n",
    "#Evaluate variance\n",
    "#Diagnostics\n",
    "test_residuals=(y_test-y_test_fitted)\n",
    "len(y_test)\n",
    "len(y_test_fitted)\n",
    "len(test_residuals)\n",
    "\n",
    "#Residuals vs. predictor\n",
    "plt.title('Residuals vs. Cost')\n",
    "plt.xlabel('Cost',fontsize=15)\n",
    "plt.scatter(x_test, test_residuals)\n",
    "plt.show()\n",
    "\n",
    "#Non-constant variance reduced, but we also reduced our coefficient of determination"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
